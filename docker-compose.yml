services:

  speaches:
    image: ghcr.io/speaches-ai/speaches:latest-cpu
    container_name: speaches
    profiles: [ "tts" ]
    ports:
      - "8969:8000"
    volumes:
      - hf-hub-cache:/home/ubuntu/.cache/huggingface/hub
    restart: always

  app:
    build: .
    network_mode: "host"
    restart: always
    depends_on:
      db:
        condition: service_healthy
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@localhost:5433/personal_guru
      - PORT=5011
      # Use env var if set, otherwise fallback to localhost (since we are on host network)
      - LLM_BASE_URL=${LLM_BASE_URL:-http://localhost:11434/v1}
      - LLM_MODEL_NAME=${LLM_MODEL_NAME:-llama3}
      - LLM_API_KEY=${LLM_API_KEY:-}
      - LLM_MAX_OUTPUT_TOKENS=${LLM_MAX_OUTPUT_TOKENS:-20000}
      - TTS_BASE_URL=${TTS_BASE_URL:-http://localhost:8969/v1}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - YOUTUBE_API_KEY=${YOUTUBE_API_KEY:-}
    volumes:
      - .:/app
    command: python run.py

  db:
    image: postgres:15
    restart: always
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=personal_guru
    volumes:
      - ./postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U postgres -d personal_guru" ]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 40s
    ports:
      - "5433:5432"

volumes:
  hf-hub-cache:
